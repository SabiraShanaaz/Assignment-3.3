1)List the components of hadoop2.X and explain each component in detail.

        *The components of hadoop 2.X are:

   1)YARN:
          -It stands Yet Another Resource Negotiator.

          -YARN is a key feature of second generation hadoop.

          -YARN is considered as a large scale,distributed operating system for big data applications.

          -YARN acts as the prerequisite for enterprise hadoop.

          -YARN provides resource management and acts as a central platform.

          -YARN provides security and data governance tools for hadoop clusters.

          -The advantage of YARN are:
                 *cost effective
                 *linear scale storage

          -YARN acts as a framework for writing data access applications that runs on hadoop clusters.
              
   2)HDFS: Hadoop Distributed File System take the data breaks them into pieces 
            and distributes them to different nodes in a cluster and thus allows parallel processing.
     
     -The two components of HDFS are:
           -Namenode
           -Datanode

     *Namenode:
              -The namenode acts as the master node.
              -It is used to store metadata.
              -It stores the information about the data nodes like
                   how many blocks are stored in the nodes,which node holds the data,node locations etc.

     *Secondary namenode:
              -secondary namenodes performs house-keeping activities for name node like periodic merging and it is used for edits.

     *Datanode:
              -The datanode acts as slave nodes.

              -The data nodes are used to store the actual data.

              -It stores the data in terms of blocks.The default size of the block is 64MB.

              -The data node acts as the heart beat of the name node as it periodically sends signals to the name node
                   to check whether it is active.


    3)Map Reduce: Map reduce is also called as distributed data processing or batch processing model 
                         because it distributes the data across several machines.

        -The two components of map reduce are:
                -Job tracker.
                -Task tracker.

        *Job Tracker:
               -The main role of job tracker is to assign the map reduce task to the task tracker.

               -It is also used to re-assign some task to the other task tracker
                         when the previous task trackers fails or when it gets shut down.

               -Job tracker also maintains the status of the task tracker.

               -It is used to control the overall execution of map reduce.

        *Task Tracker:
               -The role of the task tracker is to execute the task assigned to it by the job tracker.

               -The task tracker sends the status back to the job tracker.

               -It runs individual map-reduce tasks on the data nodes.

               -It periodically communicates with the task tracker.

          